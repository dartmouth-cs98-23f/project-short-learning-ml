{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim LDA\n",
    "\n",
    "Adapted from https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file = 'npr.csv'            # the input csv file for training\n",
    "test_file = 'money.csv'    # contains the transcript\n",
    "topic_file = 'gensim_topics_'+test_file\n",
    "\n",
    "data_path = 'data/'+csv_file\n",
    "test_path = 'data/'+test_file\n",
    "topic_path = 'topics/'+topic_file\n",
    "\n",
    "df = pd.read_csv(data_path);\n",
    "# df = df[['headline_text']]\n",
    "df = df[['Article']]\n",
    "df['index'] = df.index\n",
    "documents = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11992\n",
      "                                             Article  index\n",
      "0  In the Washington of 2016, even when the polic...      0\n",
      "1    Donald Trump has used Twitter  —   his prefe...      1\n",
      "2    Donald Trump is unabashedly praising Russian...      2\n",
      "3  Updated at 2:50 p. m. ET, Russian President Vl...      3\n",
      "4  From photography, illustration and video, to d...      4\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))\n",
    "print(documents[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/bansharee/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "stemmer = SnowballStemmer(\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words in third person are changed to first person and verbs in past and future tenses are changed into present\n",
    "# words are reduced to their root form\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['Oklahoma', 'City', 'residents', 'woke', 'early', 'New', 'Year’s', 'Day', 'to', 'a', 'magnitude', '4.', '2', 'quake.', 'Earlier', 'this', 'week,', 'a', 'magnitude', '4.', '3', 'quake', 'struck', 'the', 'same', 'area.', 'The', 'state', 'isn’t', 'historically', 'known', 'for', 'earthquakes,', 'but', 'NPR’s', 'Nell', 'Greenfieldboyce', 'told', 'our', 'Newscast', 'unit', 'that', 'Oklahoma', '”has', 'recently', 'seen', 'a', 'dramatic', 'rise', 'in', 'seismic', 'activity.”', 'Here’s', 'more:', '”If', 'you', 'think', 'of', 'a', 'U.', 'S.', 'state', 'associated', 'with', 'earthquakes,', 'it’s', 'probably', 'California.', 'But', 'really,', 'you', 'should', 'think', 'Oklahoma.', 'In', '2015,', 'Oklahoma', 'hit', 'an', '', '', 'high,', 'with', 'more', 'than', '800', 'quakes', 'of', 'magnitude', '3', 'or', 'greater.', 'That', 'busts', 'the', 'record', 'set', 'in', '2014,', 'which', 'topped', 'the', 'previous', 'record', 'set', 'the', 'year', 'before.', 'State', 'officials', 'have', 'said', 'this', 'rise', 'is', 'very', 'unlikely', 'to', 'represent', 'a', 'naturally', 'occurring', 'process.', 'The', 'concern', 'is', 'that', 'these', 'quakes', 'may', 'be', 'linked', 'to', 'oil', 'and', 'gas', 'drilling', '', '—', '', '', 'specifically,', 'the', 'way', 'wastewater', 'produced', 'by', 'the', 'drilling', 'is', 'pumped', 'into', 'deep', 'underground', 'disposal', 'wells.', 'Oklahoma', 'is', 'trying', 'to', 'address', 'the', 'issue.', 'It', 'has', 'a', 'coordinating', 'council', 'on', 'seismic', 'activity', 'that', 'includes', 'regulators,', 'scientists', 'and', 'industry', 'representatives.”', 'Joe', 'Wertz', 'of', 'StateImpact', 'Oklahoma', 'further', 'explained', 'the', 'connection', 'between', 'the', 'oil', 'and', 'gas', 'industry', 'and', 'the', 'increasing', 'number', 'of', 'quakes,', 'on', 'Weekend', 'Edition', 'Saturday', 'in', 'November:', '”Oil', 'and', 'gas', 'production', 'creates', 'a', 'lot', 'of', 'toxic', 'wastewater.', 'To', 'keep', 'it', 'from', 'contaminating', 'drinking', 'water,', 'oil', 'companies', 'inject', 'the', 'fluid', 'into', 'underground', 'disposal', 'wells.', 'That', 'can', 'put', 'pressure', 'on', 'faults,', 'causing', 'them', 'to', 'slip,', 'which', 'scientists', 'say', 'is', 'responsible', 'for', 'Oklahoma’s', 'massive', 'earthquake', 'spike.”', 'And', 'even', 'as', 'scientists', 'blame', 'the', 'oil', 'and', 'gas', 'industry', 'for', 'the', 'new', 'seismic', 'activity,', '”researchers', 'say', 'the', 'earthquakes', 'could', 'compromise', 'the', 'economically', 'vital', 'energy', 'hub.”', 'StateImpact', 'says', 'the', 'National', 'Research', 'Council', 'advises', '”investigating', 'any', 'potential', 'site’s', 'history', 'of', 'earthquakes', 'and', 'its', 'proximity', 'to', 'fault', 'lines.”', 'Other', 'scientists', 'suggest', '”that', 'companies', 'look', 'for', 'new', 'ways', 'of', 'disposing', 'of', 'wastewater', 'altogether.”']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['oklahoma', 'citi', 'resid', 'wake', 'earli', 'year', 'magnitud', 'quak', 'earlier', 'week', 'magnitud', 'quak', 'strike', 'area', 'state', 'histor', 'know', 'earthquak', 'nell', 'greenfieldboyc', 'tell', 'newscast', 'unit', 'oklahoma', 'recent', 'see', 'dramat', 'rise', 'seismic', 'activ', 'think', 'state', 'associ', 'earthquak', 'probabl', 'california', 'think', 'oklahoma', 'oklahoma', 'high', 'quak', 'magnitud', 'greater', 'bust', 'record', 'top', 'previous', 'record', 'year', 'state', 'offici', 'say', 'rise', 'unlik', 'repres', 'natur', 'occur', 'process', 'concern', 'quak', 'link', 'drill', 'specif', 'wastewat', 'produc', 'drill', 'pump', 'deep', 'underground', 'dispos', 'well', 'oklahoma', 'tri', 'address', 'issu', 'coordin', 'council', 'seismic', 'activ', 'includ', 'regul', 'scientist', 'industri', 'repres', 'wertz', 'stateimpact', 'oklahoma', 'explain', 'connect', 'industri', 'increas', 'number', 'quak', 'weekend', 'edit', 'saturday', 'novemb', 'product', 'creat', 'toxic', 'wastewat', 'contamin', 'drink', 'water', 'compani', 'inject', 'fluid', 'underground', 'dispos', 'well', 'pressur', 'fault', 'caus', 'slip', 'scientist', 'respons', 'oklahoma', 'massiv', 'earthquak', 'spike', 'scientist', 'blame', 'industri', 'seismic', 'activ', 'research', 'earthquak', 'compromis', 'econom', 'vital', 'energi', 'stateimpact', 'say', 'nation', 'research', 'council', 'advis', 'investig', 'potenti', 'site', 'histori', 'earthquak', 'proxim', 'fault', 'line', 'scientist', 'suggest', 'compani', 'look', 'way', 'dispos', 'wastewat', 'altogeth']\n"
     ]
    }
   ],
   "source": [
    "# displaying how preprocessing works\n",
    "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [washington, polici, bipartisan, polit, sens, ...\n",
       "1    [donald, trump, twitter, prefer, mean, communi...\n",
       "2    [donald, trump, unabash, prais, russian, presi...\n",
       "3    [updat, russian, presid, vladimir, putin, say,...\n",
       "4    [photographi, illustr, video, data, visual, im...\n",
       "5    [want, join, yoga, class, hat, beatif, instruc...\n",
       "6    [public, support, debunk, claim, vaccin, caus,...\n",
       "7    [stand, airport, exit, debat, snack, young, ro...\n",
       "8    [movi, tri, realist, summon, batman, shouldn, ...\n",
       "9    [eighteen, year, year, david, fisher, visit, f...\n",
       "Name: Article, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess 'headline_text' text from training set\n",
    "# processed_docs = documents['headline_text'].map(preprocess)\n",
    "processed_docs = documents['Article'].map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 abil\n",
      "1 accept\n",
      "2 account\n",
      "3 act\n",
      "4 action\n",
      "5 actual\n",
      "6 add\n",
      "7 administr\n",
      "8 advis\n",
      "9 affair\n",
      "10 afloat\n"
     ]
    }
   ],
   "source": [
    "# creating dictionary using words in the training set, mapped to how many times the word appears in the set\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out:\n",
    "#   * less than 15 documents (absolute number) or\n",
    "#   * more than 0.5 documents (fraction of total corpus size, not absolute number)\n",
    "#   * after the above two steps, keep only the first 100000 most frequent tokens\n",
    "\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 8 (\"advis\") appears 1 time.\n",
      "Word 51 (\"citi\") appears 1 time.\n",
      "Word 61 (\"compromis\") appears 1 time.\n",
      "Word 63 (\"concern\") appears 1 time.\n",
      "Word 105 (\"econom\") appears 1 time.\n",
      "Word 140 (\"greater\") appears 1 time.\n",
      "Word 158 (\"includ\") appears 1 time.\n",
      "Word 166 (\"issu\") appears 1 time.\n",
      "Word 179 (\"look\") appears 1 time.\n",
      "Word 195 (\"nation\") appears 1 time.\n",
      "Word 206 (\"offici\") appears 1 time.\n",
      "Word 247 (\"recent\") appears 1 time.\n",
      "Word 259 (\"respons\") appears 1 time.\n",
      "Word 298 (\"suggest\") appears 1 time.\n",
      "Word 314 (\"tri\") appears 1 time.\n",
      "Word 323 (\"unit\") appears 1 time.\n",
      "Word 334 (\"week\") appears 1 time.\n",
      "Word 357 (\"compani\") appears 2 time.\n",
      "Word 362 (\"council\") appears 2 time.\n",
      "Word 374 (\"earlier\") appears 1 time.\n",
      "Word 406 (\"line\") appears 1 time.\n",
      "Word 451 (\"state\") appears 3 time.\n",
      "Word 497 (\"earli\") appears 1 time.\n",
      "Word 515 (\"increas\") appears 1 time.\n",
      "Word 569 (\"unlik\") appears 1 time.\n",
      "Word 572 (\"wake\") appears 1 time.\n",
      "Word 615 (\"specif\") appears 1 time.\n",
      "Word 636 (\"area\") appears 1 time.\n",
      "Word 694 (\"creat\") appears 1 time.\n",
      "Word 737 (\"energi\") appears 1 time.\n",
      "Word 754 (\"explain\") appears 1 time.\n",
      "Word 786 (\"histori\") appears 1 time.\n",
      "Word 848 (\"number\") appears 1 time.\n",
      "Word 874 (\"potenti\") appears 1 time.\n",
      "Word 878 (\"previous\") appears 1 time.\n",
      "Word 879 (\"probabl\") appears 1 time.\n",
      "Word 894 (\"record\") appears 2 time.\n",
      "Word 898 (\"regul\") appears 1 time.\n",
      "Word 930 (\"site\") appears 1 time.\n",
      "Word 993 (\"water\") appears 1 time.\n",
      "Word 994 (\"way\") appears 1 time.\n",
      "Word 1004 (\"activ\") appears 3 time.\n",
      "Word 1166 (\"altogeth\") appears 1 time.\n",
      "Word 1188 (\"caus\") appears 1 time.\n",
      "Word 1201 (\"connect\") appears 1 time.\n",
      "Word 1237 (\"fluid\") appears 1 time.\n",
      "Word 1246 (\"high\") appears 1 time.\n",
      "Word 1251 (\"inject\") appears 1 time.\n",
      "Word 1277 (\"natur\") appears 1 time.\n",
      "Word 1285 (\"occur\") appears 1 time.\n",
      "Word 1301 (\"produc\") appears 1 time.\n",
      "Word 1302 (\"product\") appears 1 time.\n",
      "Word 1315 (\"research\") appears 2 time.\n",
      "Word 1322 (\"scientist\") appears 4 time.\n",
      "Word 1337 (\"strike\") appears 1 time.\n",
      "Word 1347 (\"toxic\") appears 1 time.\n",
      "Word 1374 (\"associ\") appears 1 time.\n",
      "Word 1394 (\"drink\") appears 1 time.\n",
      "Word 1420 (\"link\") appears 1 time.\n",
      "Word 1424 (\"magnitud\") appears 3 time.\n",
      "Word 1638 (\"see\") appears 1 time.\n",
      "Word 1662 (\"vital\") appears 1 time.\n",
      "Word 1691 (\"deep\") appears 1 time.\n",
      "Word 1886 (\"spike\") appears 1 time.\n",
      "Word 1910 (\"california\") appears 1 time.\n",
      "Word 1917 (\"dramat\") appears 1 time.\n",
      "Word 1928 (\"histor\") appears 1 time.\n",
      "Word 1955 (\"resid\") appears 1 time.\n",
      "Word 2048 (\"novemb\") appears 1 time.\n",
      "Word 2057 (\"pressur\") appears 1 time.\n",
      "Word 2058 (\"process\") appears 1 time.\n",
      "Word 2147 (\"rise\") appears 2 time.\n",
      "Word 2183 (\"edit\") appears 1 time.\n",
      "Word 2233 (\"weekend\") appears 1 time.\n",
      "Word 2564 (\"well\") appears 2 time.\n",
      "Word 2611 (\"industri\") appears 3 time.\n",
      "Word 2688 (\"newscast\") appears 1 time.\n",
      "Word 2697 (\"saturday\") appears 1 time.\n",
      "Word 2729 (\"investig\") appears 1 time.\n",
      "Word 2900 (\"blame\") appears 1 time.\n",
      "Word 3327 (\"repres\") appears 2 time.\n",
      "Word 3348 (\"slip\") appears 1 time.\n",
      "Word 3474 (\"massiv\") appears 1 time.\n",
      "Word 3662 (\"drill\") appears 2 time.\n",
      "Word 3676 (\"oklahoma\") appears 7 time.\n",
      "Word 3726 (\"address\") appears 1 time.\n",
      "Word 3787 (\"fault\") appears 2 time.\n",
      "Word 3816 (\"underground\") appears 2 time.\n",
      "Word 3988 (\"top\") appears 1 time.\n",
      "Word 4082 (\"contamin\") appears 1 time.\n",
      "Word 4502 (\"coordin\") appears 1 time.\n",
      "Word 4515 (\"proxim\") appears 1 time.\n",
      "Word 4581 (\"dispos\") appears 3 time.\n",
      "Word 5644 (\"bust\") appears 1 time.\n",
      "Word 6681 (\"pump\") appears 1 time.\n",
      "Word 7175 (\"earthquak\") appears 5 time.\n",
      "Word 7938 (\"nell\") appears 1 time.\n",
      "Word 9145 (\"seismic\") appears 3 time.\n",
      "Word 10888 (\"quak\") appears 5 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[4310]\n",
    "\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(\n",
    "                                                    bow_doc_4310[i][0], \n",
    "                                                    dictionary[bow_doc_4310[i][0]], \n",
    "                                                    bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.023067990364550667),\n",
      " (1, 0.02138290697692375),\n",
      " (2, 0.019120276543562995),\n",
      " (3, 0.023312189215803015),\n",
      " (4, 0.07177692380940279),\n",
      " (5, 0.012376338229759715),\n",
      " (6, 0.012652765926049652),\n",
      " (7, 0.015681833239163178),\n",
      " (8, 0.022752553413297974),\n",
      " (9, 0.027595984325063022),\n",
      " (10, 0.05605640784415791),\n",
      " (11, 0.055234263426146644),\n",
      " (12, 0.029834588795734765),\n",
      " (13, 0.03757301028755038),\n",
      " (14, 0.04175927604924723),\n",
      " (15, 0.046873736806329634),\n",
      " (16, 0.028261189971447376),\n",
      " (17, 0.032253677145107414),\n",
      " (18, 0.015158469095917521),\n",
      " (19, 0.009910816499937069),\n",
      " (20, 0.06389342674765507),\n",
      " (21, 0.04649554154969994),\n",
      " (22, 0.044285416005865226),\n",
      " (23, 0.027833764343638497),\n",
      " (24, 0.023250503546463713),\n",
      " (25, 0.03779800986995305),\n",
      " (26, 0.04946093135473547),\n",
      " (27, 0.0786047603506468),\n",
      " (28, 0.02922961188090144),\n",
      " (29, 0.02138290697692375),\n",
      " (30, 0.03995684959520006),\n",
      " (31, 0.023573953955485928),\n",
      " (32, 0.0321408155994278),\n",
      " (33, 0.013108675965096848),\n",
      " (34, 0.04804888404574625),\n",
      " (35, 0.026643756295786036),\n",
      " (36, 0.03774496889516698),\n",
      " (37, 0.02820288714869866),\n",
      " (38, 0.05359100101195448),\n",
      " (39, 0.012004470079129598),\n",
      " (40, 0.03785137133595704),\n",
      " (41, 0.047394414625869595),\n",
      " (42, 0.015323931467701325),\n",
      " (43, 0.04988528831633517),\n",
      " (44, 0.05780004895742308),\n",
      " (45, 0.02530607957682975),\n",
      " (46, 0.013362475769097248),\n",
      " (47, 0.052754038067894325),\n",
      " (48, 0.015530940941866894),\n",
      " (49, 0.019912069160089144),\n",
      " (50, 0.04088731946985065),\n",
      " (51, 0.013128192648741084),\n",
      " (52, 0.03900119794986026),\n",
      " (53, 0.013921517811172122),\n",
      " (54, 0.028835292107991496),\n",
      " (55, 0.02323003703497501),\n",
      " (56, 0.02150817568371135),\n",
      " (57, 0.10617446484421697),\n",
      " (58, 0.04529849922165387),\n",
      " (59, 0.014900013097375618),\n",
      " (60, 0.03679337150863408),\n",
      " (61, 0.033567826337736716),\n",
      " (62, 0.03610843180290698),\n",
      " (63, 0.031096111722954015),\n",
      " (64, 0.02718667586506468),\n",
      " (65, 0.02521602916763655),\n",
      " (66, 0.021575719383931883),\n",
      " (67, 0.029856207645587877),\n",
      " (68, 0.03655910589570113),\n",
      " (69, 0.015919816686982332),\n",
      " (70, 0.022958283416423714),\n",
      " (71, 0.05451664151643441),\n",
      " (72, 0.029109456343660196),\n",
      " (73, 0.008695441409733096),\n",
      " (74, 0.04932572363796693),\n",
      " (75, 0.04723810442577022),\n",
      " (76, 0.024766883443427493),\n",
      " (77, 0.029013854678344393),\n",
      " (78, 0.0155652040139616),\n",
      " (79, 0.025126887718245665),\n",
      " (80, 0.024155965230042462),\n",
      " (81, 0.024043175756275282),\n",
      " (82, 0.015857498817223165),\n",
      " (83, 0.01643485336109034),\n",
      " (84, 0.0235845876662888),\n",
      " (85, 0.030554074183528162),\n",
      " (86, 0.026949897720960334),\n",
      " (87, 0.03046086703068617),\n",
      " (88, 0.047394414625869595),\n",
      " (89, 0.032690238631608005),\n",
      " (90, 0.016782549056383145),\n",
      " (91, 0.023898670524856266),\n",
      " (92, 0.020118035533647896),\n",
      " (93, 0.01963563670924044),\n",
      " (94, 0.04119452594916113),\n",
      " (95, 0.043807602665850605),\n",
      " (96, 0.048573669846684646),\n",
      " (97, 0.037181622853869924),\n",
      " (98, 0.03906833064759097),\n",
      " (99, 0.04360582755603524),\n",
      " (100, 0.0382902838078568),\n",
      " (101, 0.1306418138299583),\n",
      " (102, 0.0489416937534973),\n",
      " (103, 0.05417027179886431),\n",
      " (104, 0.07966183720331212),\n",
      " (105, 0.020484836417520958),\n",
      " (106, 0.02450324309669606),\n",
      " (107, 0.08013840591073573),\n",
      " (108, 0.02168659176707966),\n",
      " (109, 0.04839525376331634),\n",
      " (110, 0.01896126440195416),\n",
      " (111, 0.018560753339895854),\n",
      " (112, 0.018780327252124314),\n",
      " (113, 0.015207783113798891),\n",
      " (114, 0.026856935854635264),\n",
      " (115, 0.04708451280219062),\n",
      " (116, 0.03043771814258307),\n",
      " (117, 0.024742588254089058),\n",
      " (118, 0.03915115011669634),\n",
      " (119, 0.017052609720696582),\n",
      " (120, 0.020789656866217858),\n",
      " (121, 0.02696548694964169),\n",
      " (122, 0.016525285096755275),\n",
      " (123, 0.015879704752369696),\n",
      " (124, 0.038693083722250485),\n",
      " (125, 0.015928755246201673),\n",
      " (126, 0.012880945170284807),\n",
      " (127, 0.05928309034357077),\n",
      " (128, 0.042600741803649596),\n",
      " (129, 0.028311247965315534),\n",
      " (130, 0.01948052023398504),\n",
      " (131, 0.02655394573443737),\n",
      " (132, 0.02937189129958177),\n",
      " (133, 0.01993315463549717),\n",
      " (134, 0.009953901607692944),\n",
      " (135, 0.021609685947937697),\n",
      " (136, 0.011639372477309024),\n",
      " (137, 0.04037415379658188),\n",
      " (138, 0.04201282348544609),\n",
      " (139, 0.028022062003101696),\n",
      " (140, 0.027170691614991048),\n",
      " (141, 0.029965102931037466),\n",
      " (142, 0.029129369082096217),\n",
      " (143, 0.13547797540969225),\n",
      " (144, 0.029468842901083942),\n",
      " (145, 0.021500534122414608),\n",
      " (146, 0.012325643500707261),\n",
      " (147, 0.008217750288243904),\n",
      " (148, 0.05902789367903279),\n",
      " (149, 0.020969813714450152),\n",
      " (150, 0.012727135171893635),\n",
      " (151, 0.032690238631608005),\n",
      " (152, 0.017645959968960512),\n",
      " (153, 0.015813253755964648),\n",
      " (154, 0.034753558596896356),\n",
      " (155, 0.01447652697953196),\n",
      " (156, 0.012852492787774247),\n",
      " (157, 0.030277352983160526),\n",
      " (158, 0.030376592437764246),\n",
      " (159, 0.02444440679809556),\n",
      " (160, 0.0497272153091533),\n",
      " (161, 0.22512225351497783),\n",
      " (162, 0.2053033654920315),\n",
      " (163, 0.027075388937372765),\n",
      " (164, 0.041273026872751535),\n",
      " (165, 0.05949727753379023),\n",
      " (166, 0.04622888118592409),\n",
      " (167, 0.017206290439040272),\n",
      " (168, 0.020851904142462296),\n",
      " (169, 0.034905132404735736),\n",
      " (170, 0.0662545616184923),\n",
      " (171, 0.020903735126912303),\n",
      " (172, 0.04693354680543424),\n",
      " (173, 0.017134239840924725),\n",
      " (174, 0.05417027179886431),\n",
      " (175, 0.035317279592637287),\n",
      " (176, 0.008806528355636866),\n",
      " (177, 0.01096684233870625),\n",
      " (178, 0.03110998901125032),\n",
      " (179, 0.02300788096155906),\n",
      " (180, 0.04094378755637981),\n",
      " (181, 0.07591814279891779),\n",
      " (182, 0.0394294513713008),\n",
      " (183, 0.009569146270743768),\n",
      " (184, 0.08251326036916103),\n",
      " (185, 0.013282584120555864),\n",
      " (186, 0.055530342820843105),\n",
      " (187, 0.02530607957682975),\n",
      " (188, 0.02191260182767926),\n",
      " (189, 0.038576111207481896),\n",
      " (190, 0.038403507099153744),\n",
      " (191, 0.0340241517534227),\n",
      " (192, 0.00988145786279479),\n",
      " (193, 0.07377769181226108),\n",
      " (194, 0.03141592270434191),\n",
      " (195, 0.017915057540237058),\n",
      " (196, 0.12133698796480434),\n",
      " (197, 0.008460081860547596),\n",
      " (198, 0.026749702845408316),\n",
      " (199, 0.012986061924348643),\n",
      " (200, 0.052064793539621304),\n",
      " (201, 0.254199039171489),\n",
      " (202, 0.10254549467895628),\n",
      " (203, 0.029921383555835204),\n",
      " (204, 0.032750112052500724),\n",
      " (205, 0.02457414470185995),\n",
      " (206, 0.013335764835298473),\n",
      " (207, 0.018854748724180206),\n",
      " (208, 0.02838423429606825),\n",
      " (209, 0.047394414625869595),\n",
      " (210, 0.03790505718976452),\n",
      " (211, 0.026132289391989354),\n",
      " (212, 0.0497272153091533),\n",
      " (213, 0.04804888404574625),\n",
      " (214, 0.04493301413784412),\n",
      " (215, 0.033212589220686276),\n",
      " (216, 0.023876647332009615),\n",
      " (217, 0.0244326864304101),\n",
      " (218, 0.03394345445024107),\n",
      " (219, 0.012880945170284807),\n",
      " (220, 0.02505119043403536),\n",
      " (221, 0.03491819920870241),\n",
      " (222, 0.034041649318633974),\n",
      " (223, 0.035763752123760345),\n",
      " (224, 0.012989266894717619),\n",
      " (225, 0.04370911874234367),\n",
      " (226, 0.045810601843972835),\n",
      " (227, 0.03129423113972537),\n",
      " (228, 0.038967800684152856),\n",
      " (229, 0.047394414625869595),\n",
      " (230, 0.032197066081031664),\n",
      " (231, 0.027595984325063022),\n",
      " (232, 0.07543047845881641),\n",
      " (233, 0.01791058788021686),\n",
      " (234, 0.023343194381956082),\n",
      " (235, 0.028274979759291254),\n",
      " (236, 0.02017570950682058),\n",
      " (237, 0.016014125852156905),\n",
      " (238, 0.029474941427469942),\n",
      " (239, 0.04088731946985065),\n",
      " (240, 0.020312483258667455),\n",
      " (241, 0.030961560378612748),\n",
      " (242, 0.018518685162162297),\n",
      " (243, 0.24689500201959175),\n",
      " (244, 0.011152337283656931),\n",
      " (245, 0.015428942166978024),\n",
      " (246, 0.014130594985723688),\n",
      " (247, 0.021150768405666053),\n",
      " (248, 0.02579794173596304),\n",
      " (249, 0.024270213857752555),\n",
      " (250, 0.026810819322922813),\n",
      " (251, 0.021145646225576013),\n",
      " (252, 0.014591071980333967),\n",
      " (253, 0.03567964390940094),\n",
      " (254, 0.02218986021219747),\n",
      " (255, 0.007057423536264057),\n",
      " (256, 0.09773559811866078),\n",
      " (257, 0.05563313219829627),\n",
      " (258, 0.01907546378319336),\n",
      " (259, 0.014931909459831236),\n",
      " (260, 0.04320433588484887),\n",
      " (261, 0.051545155681559526),\n",
      " (262, 0.01831129867729204),\n",
      " (263, 0.02762956343682941),\n",
      " (264, 0.035776460315007884),\n",
      " (265, 0.03779800986995305),\n",
      " (266, 0.017134239840924725),\n",
      " (267, 0.22916358608012724),\n",
      " (268, 0.36644981964937545),\n",
      " (269, 0.029856207645587877),\n",
      " (270, 0.24231371608045513),\n",
      " (271, 0.1337461666264441),\n",
      " (272, 0.032775254136080074),\n",
      " (273, 0.02786826163654623),\n",
      " (274, 0.0497272153091533),\n",
      " (275, 0.05999014444599241),\n",
      " (276, 0.03192920045996437),\n",
      " (277, 0.022235405933338368),\n",
      " (278, 0.017893814283997153),\n",
      " (279, 0.03597759539870593),\n",
      " (280, 0.02925145441524561),\n",
      " (281, 0.027331851119233048),\n",
      " (282, 0.04788051715048771),\n",
      " (283, 0.016141458789832128),\n",
      " (284, 0.017777282771738206),\n",
      " (285, 0.041842985640493664),\n",
      " (286, 0.031060235100751867),\n",
      " (287, 0.01868206425500239),\n",
      " (288, 0.013463367526215466),\n",
      " (289, 0.029149326821109333),\n",
      " (290, 0.05792254094600792),\n",
      " (291, 0.02456247400789372),\n",
      " (292, 0.015560913853199656),\n",
      " (293, 0.04932572363796693),\n",
      " (294, 0.01874950245379727),\n",
      " (295, 0.0319193294890811),\n",
      " (296, 0.022485496043596925),\n",
      " (297, 0.025894159139522144),\n",
      " (298, 0.049389932511378284),\n",
      " (299, 0.022535287346768587),\n",
      " (300, 0.015552339778977834),\n",
      " (301, 0.04151280528722778),\n",
      " (302, 0.05453406795738814),\n",
      " (303, 0.026628724299382664),\n",
      " (304, 0.012991927272701946),\n",
      " (305, 0.041273026872751535),\n",
      " (306, 0.020820725660811355),\n",
      " (307, 0.028663434443020025),\n",
      " (308, 0.007608080347794689),\n",
      " (309, 0.022560977663399328),\n",
      " (310, 0.024201487473903514),\n",
      " (311, 0.043106751513443245),\n",
      " (312, 0.07873137445204814),\n",
      " (313, 0.023499874347615617),\n",
      " (314, 0.010941384564505252),\n",
      " (315, 0.01964925474702721),\n",
      " (316, 0.23755407388394062),\n",
      " (317, 0.01163112278427121),\n",
      " (318, 0.0220994674501101),\n",
      " (319, 0.019301836742227598),\n",
      " (320, 0.023489342091442073),\n",
      " (321, 0.042452282093566586),\n",
      " (322, 0.03343698993353568),\n",
      " (323, 0.013456605431126447),\n",
      " (324, 0.05411920933817456),\n",
      " (325, 0.02065882046201682),\n",
      " (326, 0.0237890996930625),\n",
      " (327, 0.03194671337382753),\n",
      " (328, 0.035763752123760345),\n",
      " (329, 0.01746852157392519),\n",
      " (330, 0.013974576423957575),\n",
      " (331, 0.03703402116029891),\n",
      " (332, 0.031363666478326356),\n",
      " (333, 0.04771558804744726),\n",
      " (334, 0.07104559397915955),\n",
      " (335, 0.013069771515595071),\n",
      " (336, 0.03717111012853028),\n",
      " (337, 0.033502165843783),\n",
      " (338, 0.010077514297358358)]\n",
      "abil 0.023067990364550667\n",
      "accept 0.02138290697692375\n",
      "account 0.019120276543562995\n",
      "act 0.023312189215803015\n",
      "action 0.07177692380940279\n",
      "actual 0.012376338229759715\n",
      "add 0.012652765926049652\n",
      "administr 0.015681833239163178\n",
      "advis 0.022752553413297974\n",
      "affair 0.027595984325063022\n",
      "afloat 0.05605640784415791\n",
      "agenc 0.055234263426146644\n",
      "aggress 0.029834588795734765\n",
      "agre 0.03757301028755038\n",
      "aleppo 0.04175927604924723\n",
      "alleg 0.046873736806329634\n",
      "allow 0.028261189971447376\n",
      "alongsid 0.032253677145107414\n",
      "america 0.015158469095917521\n",
      "american 0.009910816499937069\n",
      "amount 0.06389342674765507\n",
      "annex 0.04649554154969994\n",
      "appear 0.044285416005865226\n",
      "appropri 0.027833764343638497\n",
      "approv 0.023250503546463713\n",
      "aris 0.03779800986995305\n",
      "arm 0.04946093135473547\n",
      "assad 0.0786047603506468\n",
      "assess 0.02922961188090144\n",
      "avail 0.02138290697692375\n",
      "bashar 0.03995684959520006\n",
      "battl 0.023573953955485928\n",
      "behalf 0.0321408155994278\n",
      "believ 0.013108675965096848\n",
      "besieg 0.04804888404574625\n",
      "bigger 0.026643756295786036\n",
      "bipartisan 0.03774496889516698\n",
      "bomb 0.02820288714869866\n",
      "brief 0.05359100101195448\n",
      "bring 0.012004470079129598\n",
      "bulli 0.03785137133595704\n",
      "burr 0.047394414625869595\n",
      "busi 0.015323931467701325\n",
      "call 0.04988528831633517\n",
      "campaign 0.05780004895742308\n",
      "cast 0.02530607957682975\n",
      "center 0.013362475769097248\n",
      "chairman 0.052754038067894325\n",
      "children 0.015530940941866894\n",
      "choos 0.019912069160089144\n",
      "chorus 0.04088731946985065\n",
      "citi 0.013128192648741084\n",
      "clinton 0.03900119794986026\n",
      "close 0.013921517811172122\n",
      "closer 0.028835292107991496\n",
      "colleagu 0.02323003703497501\n",
      "commit 0.02150817568371135\n",
      "committe 0.10617446484421697\n",
      "commod 0.04529849922165387\n",
      "communiti 0.014900013097375618\n",
      "compound 0.03679337150863408\n",
      "compromis 0.033567826337736716\n",
      "comput 0.03610843180290698\n",
      "concern 0.031096111722954015\n",
      "conclud 0.02718667586506468\n",
      "confid 0.02521602916763655\n",
      "confirm 0.021575719383931883\n",
      "confront 0.029856207645587877\n",
      "consensus 0.03655910589570113\n",
      "control 0.015919816686982332\n",
      "controversi 0.022958283416423714\n",
      "conundrum 0.05451664151643441\n",
      "cooper 0.029109456343660196\n",
      "countri 0.008695441409733096\n",
      "covert 0.04932572363796693\n",
      "crimea 0.04723810442577022\n",
      "crisi 0.024766883443427493\n",
      "critic 0.029013854678344393\n",
      "current 0.0155652040139616\n",
      "daili 0.025126887718245665\n",
      "damag 0.024155965230042462\n",
      "date 0.024043175756275282\n",
      "deal 0.015857498817223165\n",
      "decid 0.01643485336109034\n",
      "declin 0.0235845876662888\n",
      "defeat 0.030554074183528162\n",
      "defin 0.026949897720960334\n",
      "delay 0.03046086703068617\n",
      "delv 0.047394414625869595\n",
      "democraci 0.032690238631608005\n",
      "democrat 0.016782549056383145\n",
      "deni 0.023898670524856266\n",
      "design 0.020118035533647896\n",
      "despit 0.01963563670924044\n",
      "deter 0.04119452594916113\n",
      "determin 0.043807602665850605\n",
      "devin 0.048573669846684646\n",
      "dictat 0.037181622853869924\n",
      "difficult 0.03906833064759097\n",
      "dilemma 0.04360582755603524\n",
      "diminish 0.0382902838078568\n",
      "diplomat 0.1306418138299583\n",
      "discredit 0.0489416937534973\n",
      "dispel 0.05417027179886431\n",
      "doubt 0.07966183720331212\n",
      "econom 0.020484836417520958\n",
      "economi 0.02450324309669606\n",
      "elect 0.08013840591073573\n",
      "email 0.02168659176707966\n",
      "embattl 0.04839525376331634\n",
      "end 0.01896126440195416\n",
      "entir 0.018560753339895854\n",
      "evid 0.018780327252124314\n",
      "exampl 0.015207783113798891\n",
      "exchang 0.026856935854635264\n",
      "expel 0.04708451280219062\n",
      "extens 0.03043771814258307\n",
      "eye 0.024742588254089058\n",
      "face 0.03915115011669634\n",
      "fall 0.017052609720696582\n",
      "fear 0.020789656866217858\n",
      "fell 0.02696548694964169\n",
      "fight 0.016525285096755275\n",
      "final 0.015879704752369696\n",
      "flynn 0.038693083722250485\n",
      "focus 0.015928755246201673\n",
      "follow 0.012880945170284807\n",
      "forc 0.05928309034357077\n",
      "foreign 0.042600741803649596\n",
      "frank 0.028311247965315534\n",
      "free 0.01948052023398504\n",
      "frequent 0.02655394573443737\n",
      "function 0.02937189129958177\n",
      "fund 0.01993315463549717\n",
      "give 0.009953901607692944\n",
      "goal 0.021609685947937697\n",
      "govern 0.011639372477309024\n",
      "graham 0.04037415379658188\n",
      "grasp 0.04201282348544609\n",
      "great 0.028022062003101696\n",
      "greater 0.027170691614991048\n",
      "greatest 0.029965102931037466\n",
      "guid 0.029129369082096217\n",
      "hack 0.13547797540969225\n",
      "hand 0.029468842901083942\n",
      "happen 0.021500534122414608\n",
      "hear 0.012325643500707261\n",
      "help 0.008217750288243904\n",
      "herring 0.05902789367903279\n",
      "hillari 0.020969813714450152\n",
      "hold 0.012727135171893635\n",
      "holiday 0.032690238631608005\n",
      "hope 0.017645959968960512\n",
      "hour 0.015813253755964648\n",
      "hous 0.034753558596896356\n",
      "idea 0.01447652697953196\n",
      "import 0.012852492787774247\n",
      "impos 0.030277352983160526\n",
      "includ 0.030376592437764246\n",
      "incom 0.02444440679809556\n",
      "ineffect 0.0497272153091533\n",
      "intellig 0.22512225351497783\n",
      "interfer 0.2053033654920315\n",
      "invit 0.027075388937372765\n",
      "ironi 0.041273026872751535\n",
      "isi 0.05949727753379023\n",
      "issu 0.04622888118592409\n",
      "john 0.017206290439040272\n",
      "join 0.020851904142462296\n",
      "keep 0.034905132404735736\n",
      "leader 0.0662545616184923\n",
      "leav 0.020903735126912303\n",
      "legitimaci 0.04693354680543424\n",
      "level 0.017134239840924725\n",
      "lindsay 0.05417027179886431\n",
      "littl 0.035317279592637287\n",
      "live 0.008806528355636866\n",
      "long 0.01096684233870625\n",
      "longtim 0.03110998901125032\n",
      "look 0.02300788096155906\n",
      "major 0.04094378755637981\n",
      "mccain 0.07591814279891779\n",
      "mcconnel 0.0394294513713008\n",
      "mean 0.009569146270743768\n",
      "measur 0.08251326036916103\n",
      "member 0.013282584120555864\n",
      "mike 0.055530342820843105\n",
      "minist 0.02530607957682975\n",
      "miss 0.02191260182767926\n",
      "mitch 0.038576111207481896\n",
      "mitt 0.038403507099153744\n",
      "moment 0.0340241517534227\n",
      "month 0.00988145786279479\n",
      "moscow 0.07377769181226108\n",
      "move 0.03141592270434191\n",
      "nation 0.017915057540237058\n",
      "nato 0.12133698796480434\n",
      "need 0.008460081860547596\n",
      "neighbor 0.026749702845408316\n",
      "news 0.012986061924348643\n",
      "nune 0.052064793539621304\n",
      "obama 0.254199039171489\n",
      "occas 0.10254549467895628\n",
      "occasion 0.029921383555835204\n",
      "odd 0.032750112052500724\n",
      "offic 0.02457414470185995\n",
      "offici 0.013335764835298473\n",
      "oper 0.018854748724180206\n",
      "oppon 0.02838423429606825\n",
      "outgo 0.047394414625869595\n",
      "oval 0.03790505718976452\n",
      "overal 0.026132289391989354\n",
      "overdu 0.0497272153091533\n",
      "overst 0.04804888404574625\n",
      "overt 0.04493301413784412\n",
      "packag 0.033212589220686276\n",
      "page 0.023876647332009615\n",
      "pain 0.0244326864304101\n",
      "parti 0.03394345445024107\n",
      "past 0.012880945170284807\n",
      "paul 0.02505119043403536\n",
      "penc 0.03491819920870241\n",
      "perceiv 0.034041649318633974\n",
      "philosophi 0.035763752123760345\n",
      "play 0.012989266894717619\n",
      "pois 0.04370911874234367\n",
      "poland 0.045810601843972835\n",
      "polici 0.03129423113972537\n",
      "polit 0.038967800684152856\n",
      "politic 0.047394414625869595\n",
      "portion 0.032197066081031664\n",
      "prefer 0.027595984325063022\n",
      "presid 0.07543047845881641\n",
      "presidenti 0.01791058788021686\n",
      "price 0.023343194381956082\n",
      "prime 0.028274979759291254\n",
      "privat 0.02017570950682058\n",
      "program 0.016014125852156905\n",
      "promin 0.029474941427469942\n",
      "provoc 0.04088731946985065\n",
      "public 0.020312483258667455\n",
      "punish 0.030961560378612748\n",
      "push 0.018518685162162297\n",
      "putin 0.24689500201959175\n",
      "question 0.011152337283656931\n",
      "real 0.015428942166978024\n",
      "reason 0.014130594985723688\n",
      "recent 0.021150768405666053\n",
      "recommend 0.02579794173596304\n",
      "refus 0.024270213857752555\n",
      "reject 0.026810819322922813\n",
      "relationship 0.021145646225576013\n",
      "releas 0.014591071980333967\n",
      "reluct 0.03567964390940094\n",
      "repeat 0.02218986021219747\n",
      "report 0.007057423536264057\n",
      "republican 0.09773559811866078\n",
      "resist 0.05563313219829627\n",
      "respond 0.01907546378319336\n",
      "respons 0.014931909459831236\n",
      "retali 0.04320433588484887\n",
      "retribut 0.051545155681559526\n",
      "return 0.01831129867729204\n",
      "richard 0.02762956343682941\n",
      "role 0.035776460315007884\n",
      "romney 0.03779800986995305\n",
      "rule 0.017134239840924725\n",
      "russia 0.22916358608012724\n",
      "russian 0.36644981964937545\n",
      "ryan 0.029856207645587877\n",
      "sanction 0.24231371608045513\n",
      "scarc 0.1337461666264441\n",
      "secur 0.032775254136080074\n",
      "select 0.02786826163654623\n",
      "sen 0.0497272153091533\n",
      "senat 0.05999014444599241\n",
      "send 0.03192920045996437\n",
      "senior 0.022235405933338368\n",
      "sens 0.017893814283997153\n",
      "server 0.03597759539870593\n",
      "servic 0.02925145441524561\n",
      "sever 0.027331851119233048\n",
      "show 0.04788051715048771\n",
      "sign 0.016141458789832128\n",
      "similar 0.017777282771738206\n",
      "slat 0.041842985640493664\n",
      "smart 0.031060235100751867\n",
      "sound 0.01868206425500239\n",
      "speak 0.013463367526215466\n",
      "speaker 0.029149326821109333\n",
      "spurn 0.05792254094600792\n",
      "stage 0.02456247400789372\n",
      "stand 0.015560913853199656\n",
      "steadfast 0.04932572363796693\n",
      "strong 0.01874950245379727\n",
      "stronger 0.0319193294890811\n",
      "subject 0.022485496043596925\n",
      "sudden 0.025894159139522144\n",
      "suggest 0.049389932511378284\n",
      "support 0.022535287346768587\n",
      "sure 0.015552339778977834\n",
      "surrog 0.04151280528722778\n",
      "syria 0.05453406795738814\n",
      "system 0.026628724299382664\n",
      "take 0.012991927272701946\n",
      "talli 0.041273026872751535\n",
      "target 0.020820725660811355\n",
      "theme 0.028663434443020025\n",
      "thing 0.007608080347794689\n",
      "threat 0.022560977663399328\n",
      "tie 0.024201487473903514\n",
      "tongu 0.043106751513443245\n",
      "tougher 0.07873137445204814\n",
      "trade 0.023499874347615617\n",
      "tri 0.010941384564505252\n",
      "true 0.01964925474702721\n",
      "trump 0.23755407388394062\n",
      "turn 0.01163112278427121\n",
      "tweet 0.0220994674501101\n",
      "twitter 0.019301836742227598\n",
      "typic 0.023489342091442073\n",
      "ukrain 0.042452282093566586\n",
      "undermin 0.03343698993353568\n",
      "unit 0.013456605431126447\n",
      "urg 0.05411920933817456\n",
      "usual 0.02065882046201682\n",
      "vice 0.0237890996930625\n",
      "visibl 0.03194671337382753\n",
      "vladimir 0.035763752123760345\n",
      "vote 0.01746852157392519\n",
      "want 0.013974576423957575\n",
      "warrant 0.03703402116029891\n",
      "washington 0.031363666478326356\n",
      "weaker 0.04771558804744726\n",
      "week 0.07104559397915955\n",
      "white 0.013069771515595071\n",
      "world 0.03717111012853028\n",
      "worldwid 0.033502165843783\n",
      "write 0.010077514297358358\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF weights words based on how often they appear in a document \n",
    "# versus how often they appear in the entire corpus\n",
    "# this helps LDA distinguish topics by weighting more important words higher\n",
    "\n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "\n",
    "# preview of how this works\n",
    "pprint(corpus_tfidf[0])\n",
    "for i in range(len(bow_corpus[0])):\n",
    "    print(dictionary[bow_corpus[0][i][0]], corpus_tfidf[0][i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: HDP goes here for num_topics\n",
    "# see https://medium.com/analytics-vidhya/text-classification-using-lda-35d5b98d4f05 for HDP \n",
    "\n",
    "num_topics = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Words: 0.004*\"want\" + 0.004*\"thing\" + 0.004*\"school\" + 0.003*\"state\" + 0.003*\"report\" + 0.003*\"polic\" + 0.003*\"live\" + 0.003*\"right\" + 0.003*\"take\" + 0.003*\"write\"\n",
      "Topic: 1 Words: 0.005*\"health\" + 0.003*\"care\" + 0.003*\"help\" + 0.003*\"need\" + 0.003*\"state\" + 0.003*\"want\" + 0.003*\"studi\" + 0.003*\"look\" + 0.003*\"live\" + 0.003*\"research\"\n",
      "Topic: 2 Words: 0.014*\"trump\" + 0.007*\"state\" + 0.006*\"clinton\" + 0.006*\"presid\" + 0.005*\"report\" + 0.004*\"campaign\" + 0.004*\"countri\" + 0.003*\"vote\" + 0.003*\"nation\" + 0.003*\"elect\"\n"
     ]
    }
   ],
   "source": [
    "# training the model using the bow corpus\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=num_topics, id2word=dictionary, passes=2, workers=2)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} Words: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.006*\"trump\" + 0.002*\"clinton\" + 0.002*\"presid\" + 0.002*\"republican\" + 0.002*\"elect\" + 0.002*\"health\" + 0.002*\"vote\" + 0.002*\"obama\" + 0.002*\"state\" + 0.002*\"campaign\"\n",
      "Topic: 1 Word: 0.002*\"music\" + 0.002*\"trump\" + 0.001*\"song\" + 0.001*\"clinton\" + 0.001*\"vote\" + 0.001*\"report\" + 0.001*\"album\" + 0.001*\"stori\" + 0.001*\"citi\" + 0.001*\"patient\"\n",
      "Topic: 2 Word: 0.002*\"clinton\" + 0.002*\"trump\" + 0.001*\"polic\" + 0.001*\"women\" + 0.001*\"student\" + 0.001*\"song\" + 0.001*\"studi\" + 0.001*\"state\" + 0.001*\"report\" + 0.001*\"school\"\n"
     ]
    }
   ],
   "source": [
    "# training the model using the bow corpus\n",
    "\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=num_topics, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oklahoma', 'citi', 'resid', 'wake', 'earli', 'year', 'magnitud', 'quak', 'earlier', 'week', 'magnitud', 'quak', 'strike', 'area', 'state', 'histor', 'know', 'earthquak', 'nell', 'greenfieldboyc', 'tell', 'newscast', 'unit', 'oklahoma', 'recent', 'see', 'dramat', 'rise', 'seismic', 'activ', 'think', 'state', 'associ', 'earthquak', 'probabl', 'california', 'think', 'oklahoma', 'oklahoma', 'high', 'quak', 'magnitud', 'greater', 'bust', 'record', 'top', 'previous', 'record', 'year', 'state', 'offici', 'say', 'rise', 'unlik', 'repres', 'natur', 'occur', 'process', 'concern', 'quak', 'link', 'drill', 'specif', 'wastewat', 'produc', 'drill', 'pump', 'deep', 'underground', 'dispos', 'well', 'oklahoma', 'tri', 'address', 'issu', 'coordin', 'council', 'seismic', 'activ', 'includ', 'regul', 'scientist', 'industri', 'repres', 'wertz', 'stateimpact', 'oklahoma', 'explain', 'connect', 'industri', 'increas', 'number', 'quak', 'weekend', 'edit', 'saturday', 'novemb', 'product', 'creat', 'toxic', 'wastewat', 'contamin', 'drink', 'water', 'compani', 'inject', 'fluid', 'underground', 'dispos', 'well', 'pressur', 'fault', 'caus', 'slip', 'scientist', 'respons', 'oklahoma', 'massiv', 'earthquak', 'spike', 'scientist', 'blame', 'industri', 'seismic', 'activ', 'research', 'earthquak', 'compromis', 'econom', 'vital', 'energi', 'stateimpact', 'say', 'nation', 'research', 'council', 'advis', 'investig', 'potenti', 'site', 'histori', 'earthquak', 'proxim', 'fault', 'line', 'scientist', 'suggest', 'compani', 'look', 'way', 'dispos', 'wastewat', 'altogeth']\n",
      "\n",
      "Score: 0.5735888481140137\t \n",
      "Topic: 0.005*\"health\" + 0.003*\"care\" + 0.003*\"help\" + 0.003*\"need\" + 0.003*\"state\"\n",
      "\n",
      "Score: 0.42354097962379456\t \n",
      "Topic: 0.014*\"trump\" + 0.007*\"state\" + 0.006*\"clinton\" + 0.006*\"presid\" + 0.005*\"report\"\n"
     ]
    }
   ],
   "source": [
    "# check how part of the training set is classified\n",
    "# first appearing topic is the one assigned to it\n",
    "print(processed_docs[4310])\n",
    "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.945931613445282\t \n",
      "Topic: 0.002*\"music\" + 0.002*\"trump\" + 0.001*\"song\" + 0.001*\"clinton\" + 0.001*\"vote\"\n",
      "\n",
      "Score: 0.05070444196462631\t \n",
      "Topic: 0.006*\"trump\" + 0.002*\"clinton\" + 0.002*\"presid\" + 0.002*\"republican\" + 0.002*\"elect\"\n"
     ]
    }
   ],
   "source": [
    "# evaluate the tfidf version\n",
    "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 0.06368509), (1, 0.06775403), (2, 0.8685609)],\n",
      " [(0, 0.17948042), (1, 0.21530297), (2, 0.60521656)],\n",
      " [(0, 0.80160165), (1, 0.09750986), (2, 0.10088849)],\n",
      " [(0, 0.060702354), (1, 0.06941794), (2, 0.86987966)],\n",
      " [(0, 0.048654966), (1, 0.052578095), (2, 0.89876693)],\n",
      " [(0, 0.08876355), (1, 0.08056355), (2, 0.83067286)],\n",
      " [(0, 0.10297102), (1, 0.105059825), (2, 0.7919692)],\n",
      " [(0, 0.09844649), (1, 0.62668407), (2, 0.27486947)],\n",
      " [(0, 0.096074216), (1, 0.7944771), (2, 0.10944868)],\n",
      " [(0, 0.09452536), (1, 0.102656566), (2, 0.8028181)],\n",
      " [(0, 0.065517455), (1, 0.17258857), (2, 0.7618939)],\n",
      " [(0, 0.06674719), (1, 0.06720671), (2, 0.86604613)],\n",
      " [(0, 0.10952174), (1, 0.10294947), (2, 0.78752875)],\n",
      " [(0, 0.89448845), (1, 0.054179635), (2, 0.051331926)],\n",
      " [(0, 0.03954476), (1, 0.9202981), (2, 0.040157195)],\n",
      " [(0, 0.11109244), (1, 0.09428943), (2, 0.7946181)],\n",
      " [(0, 0.10793408), (1, 0.10577496), (2, 0.78629094)],\n",
      " [(0, 0.9134531), (1, 0.04282846), (2, 0.04371845)],\n",
      " [(0, 0.04151245), (1, 0.46400774), (2, 0.49447986)],\n",
      " [(0, 0.87776625), (1, 0.05944533), (2, 0.06278838)],\n",
      " [(0, 0.7958131), (1, 0.09878557), (2, 0.105401345)],\n",
      " [(0, 0.14016816), (1, 0.7118632), (2, 0.14796859)],\n",
      " [(0, 0.19353993), (1, 0.7547559), (2, 0.05170413)],\n",
      " [(0, 0.33333334), (1, 0.33333334), (2, 0.33333334)],\n",
      " [(0, 0.08323186), (1, 0.83713716), (2, 0.07963096)],\n",
      " [(0, 0.21801136), (1, 0.7313544), (2, 0.05063421)],\n",
      " [(0, 0.793654), (1, 0.10865307), (2, 0.09769293)],\n",
      " [(0, 0.89463073), (1, 0.051966365), (2, 0.053402916)],\n",
      " [(0, 0.9187484), (1, 0.041943762), (2, 0.03930787)],\n",
      " [(0, 0.33333334), (1, 0.33333334), (2, 0.33333334)],\n",
      " [(0, 0.8707863), (1, 0.0646523), (2, 0.06456134)],\n",
      " [(0, 0.24396832), (1, 0.19228816), (2, 0.56374353)],\n",
      " [(0, 0.13853422), (1, 0.1014752), (2, 0.7599906)],\n",
      " [(0, 0.8932109), (1, 0.05573024), (2, 0.05105886)],\n",
      " [(0, 0.8810026), (1, 0.059016112), (2, 0.05998126)],\n",
      " [(0, 0.66234946), (1, 0.05307914), (2, 0.2845714)],\n",
      " [(0, 0.88617826), (1, 0.057819963), (2, 0.056001794)],\n",
      " [(0, 0.33333334), (1, 0.33333334), (2, 0.33333334)],\n",
      " [(0, 0.08364329), (1, 0.075632125), (2, 0.84072465)],\n",
      " [(0, 0.10607682), (1, 0.097102106), (2, 0.79682106)],\n",
      " [(0, 0.8996743), (1, 0.050778326), (2, 0.049547393)],\n",
      " [(0, 0.21178518), (1, 0.226475), (2, 0.5617398)],\n",
      " [(0, 0.6283627), (1, 0.18611151), (2, 0.18552579)],\n",
      " [(0, 0.14562939), (1, 0.14688319), (2, 0.7074874)],\n",
      " [(0, 0.8448888), (1, 0.07835148), (2, 0.07675968)],\n",
      " [(0, 0.9028239), (1, 0.048109714), (2, 0.049066365)],\n",
      " [(0, 0.7996825), (1, 0.09947986), (2, 0.10083761)],\n",
      " [(0, 0.6234832), (1, 0.17896208), (2, 0.19755474)],\n",
      " [(0, 0.9154373), (1, 0.042251747), (2, 0.042310905)],\n",
      " [(0, 0.80373186), (1, 0.09538506), (2, 0.10088311)],\n",
      " [(0, 0.7349203), (1, 0.13363676), (2, 0.13144293)],\n",
      " [(0, 0.79019517), (1, 0.105046846), (2, 0.10475799)],\n",
      " [(0, 0.8715193), (1, 0.062246818), (2, 0.066233836)],\n",
      " [(0, 0.33333334), (1, 0.33333334), (2, 0.33333334)],\n",
      " [(0, 0.0743165), (1, 0.8691103), (2, 0.056573223)],\n",
      " [(0, 0.13145946), (1, 0.14211619), (2, 0.7264244)],\n",
      " [(0, 0.85015845), (1, 0.07700679), (2, 0.07283478)],\n",
      " [(0, 0.8893054), (1, 0.054554857), (2, 0.056139745)],\n",
      " [(0, 0.3778024), (1, 0.095816605), (2, 0.526381)],\n",
      " [(0, 0.11165945), (1, 0.04939434), (2, 0.8389462)],\n",
      " [(0, 0.80539787), (1, 0.09946195), (2, 0.09514021)],\n",
      " [(0, 0.63954717), (1, 0.1814925), (2, 0.1789603)],\n",
      " [(0, 0.7578827), (1, 0.12155244), (2, 0.12056483)],\n",
      " [(0, 0.87011695), (1, 0.064053185), (2, 0.0658299)],\n",
      " [(0, 0.6282634), (1, 0.18617956), (2, 0.18555702)],\n",
      " [(0, 0.8476869), (1, 0.07515981), (2, 0.07715335)],\n",
      " [(0, 0.8462991), (1, 0.07730957), (2, 0.0763913)],\n",
      " [(0, 0.33333334), (1, 0.33333334), (2, 0.33333334)],\n",
      " [(0, 0.88817745), (1, 0.05761676), (2, 0.054205813)],\n",
      " [(0, 0.7544621), (1, 0.12347048), (2, 0.12206737)],\n",
      " [(0, 0.8602641), (1, 0.07547776), (2, 0.06425811)],\n",
      " [(0, 0.8396352), (1, 0.08172922), (2, 0.078635655)],\n",
      " [(0, 0.33333334), (1, 0.33333334), (2, 0.33333334)],\n",
      " [(0, 0.8452925), (1, 0.07795343), (2, 0.07675401)],\n",
      " [(0, 0.8257346), (1, 0.091965556), (2, 0.082299866)],\n",
      " [(0, 0.8507801), (1, 0.07442027), (2, 0.07479961)],\n",
      " [(0, 0.8682662), (1, 0.06521611), (2, 0.06651766)],\n",
      " [(0, 0.08531058), (1, 0.8331945), (2, 0.081494875)],\n",
      " [(0, 0.5474597), (1, 0.25105152), (2, 0.20148876)],\n",
      " [(0, 0.113816), (1, 0.78706735), (2, 0.09911669)],\n",
      " [(0, 0.21317255), (1, 0.24415724), (2, 0.5426702)],\n",
      " [(0, 0.8627643), (1, 0.06732723), (2, 0.06990842)],\n",
      " [(0, 0.8046727), (1, 0.099110305), (2, 0.09621699)],\n",
      " [(0, 0.8908008), (1, 0.0548768), (2, 0.05432244)],\n",
      " [(0, 0.834653), (1, 0.080671564), (2, 0.084675476)],\n",
      " [(0, 0.6812164), (1, 0.17168754), (2, 0.14709604)],\n",
      " [(0, 0.88322407), (1, 0.060228094), (2, 0.056547824)],\n",
      " [(0, 0.74815196), (1, 0.12688783), (2, 0.1249602)],\n",
      " [(0, 0.86993116), (1, 0.06437563), (2, 0.0656932)],\n",
      " [(0, 0.8493621), (1, 0.07444033), (2, 0.07619759)],\n",
      " [(0, 0.5936801), (1, 0.19777179), (2, 0.20854811)],\n",
      " [(0, 0.8946808), (1, 0.053646445), (2, 0.05167274)],\n",
      " [(0, 0.90683794), (1, 0.046699937), (2, 0.04646209)],\n",
      " [(0, 0.73374647), (1, 0.13547121), (2, 0.13078235)],\n",
      " [(0, 0.88632166), (1, 0.05751639), (2, 0.056161948)],\n",
      " [(0, 0.05208538), (1, 0.8920682), (2, 0.055846438)],\n",
      " [(0, 0.8871724), (1, 0.06022884), (2, 0.052598767)],\n",
      " [(0, 0.9128459), (1, 0.044066373), (2, 0.043087684)],\n",
      " [(0, 0.91300446), (1, 0.044470012), (2, 0.042525552)],\n",
      " [(0, 0.84921354), (1, 0.07520252), (2, 0.075584)],\n",
      " [(0, 0.8721246), (1, 0.064628795), (2, 0.06324655)],\n",
      " [(0, 0.9118631), (1, 0.043991264), (2, 0.04414564)],\n",
      " [(0, 0.1843723), (1, 0.6758125), (2, 0.13981517)],\n",
      " [(0, 0.8917349), (1, 0.054598317), (2, 0.053666767)],\n",
      " [(0, 0.89867467), (1, 0.04916834), (2, 0.05215699)],\n",
      " [(0, 0.14557604), (1, 0.71005994), (2, 0.14436406)],\n",
      " [(0, 0.7263185), (1, 0.13791902), (2, 0.1357625)],\n",
      " [(0, 0.67495567), (1, 0.28744182), (2, 0.037602514)],\n",
      " [(0, 0.80994844), (1, 0.098393), (2, 0.09165851)],\n",
      " [(0, 0.9284296), (1, 0.03638392), (2, 0.035186417)],\n",
      " [(0, 0.8139842), (1, 0.09440231), (2, 0.09161346)],\n",
      " [(0, 0.75359106), (1, 0.1702148), (2, 0.07619407)],\n",
      " [(0, 0.80310345), (1, 0.09718443), (2, 0.09971212)],\n",
      " [(0, 0.7425691), (1, 0.12750264), (2, 0.12992826)],\n",
      " [(0, 0.89533514), (1, 0.051960975), (2, 0.052703876)],\n",
      " [(0, 0.8425991), (1, 0.07785452), (2, 0.0795464)],\n",
      " [(0, 0.8119689), (1, 0.09527211), (2, 0.092758976)],\n",
      " [(0, 0.22082162), (1, 0.65546787), (2, 0.12371052)],\n",
      " [(0, 0.7417624), (1, 0.12862243), (2, 0.12961514)],\n",
      " [(0, 0.28328958), (1, 0.6620517), (2, 0.05465877)],\n",
      " [(0, 0.63952696), (1, 0.18151921), (2, 0.1789538)],\n",
      " [(0, 0.8303394), (1, 0.07994347), (2, 0.08971721)],\n",
      " [(0, 0.86893225), (1, 0.06613037), (2, 0.064937375)],\n",
      " [(0, 0.74418384), (1, 0.12808472), (2, 0.12773149)],\n",
      " [(0, 0.83763593), (1, 0.08164966), (2, 0.08071442)],\n",
      " [(0, 0.20765336), (1, 0.69599694), (2, 0.09634968)],\n",
      " [(0, 0.8268228), (1, 0.086499244), (2, 0.08667794)],\n",
      " [(0, 0.0636247), (1, 0.2754371), (2, 0.6609382)],\n",
      " [(0, 0.80885017), (1, 0.09559326), (2, 0.0955566)],\n",
      " [(0, 0.8505716), (1, 0.077147014), (2, 0.07228142)],\n",
      " [(0, 0.76416147), (1, 0.18404731), (2, 0.051791243)],\n",
      " [(0, 0.8880748), (1, 0.055912483), (2, 0.05601273)],\n",
      " [(0, 0.8477131), (1, 0.0773016), (2, 0.07498529)],\n",
      " [(0, 0.90519834), (1, 0.047644064), (2, 0.047157582)],\n",
      " [(0, 0.85945493), (1, 0.0737823), (2, 0.06676279)],\n",
      " [(0, 0.5951997), (1, 0.20782699), (2, 0.1969733)],\n",
      " [(0, 0.8924978), (1, 0.054268807), (2, 0.05323339)],\n",
      " [(0, 0.88867533), (1, 0.055410396), (2, 0.055914305)],\n",
      " [(0, 0.098125696), (1, 0.7956155), (2, 0.10625878)],\n",
      " [(0, 0.91444105), (1, 0.04329921), (2, 0.042259764)],\n",
      " [(0, 0.7998385), (1, 0.10239819), (2, 0.09776334)],\n",
      " [(0, 0.8866617), (1, 0.05658665), (2, 0.056751676)],\n",
      " [(0, 0.0602069), (1, 0.8797975), (2, 0.059995607)],\n",
      " [(0, 0.73383546), (1, 0.20968336), (2, 0.056481164)],\n",
      " [(0, 0.87866), (1, 0.05962343), (2, 0.06171653)],\n",
      " [(0, 0.79948395), (1, 0.10250642), (2, 0.0980096)],\n",
      " [(0, 0.91169304), (1, 0.04430948), (2, 0.043997448)],\n",
      " [(0, 0.67406434), (1, 0.04837876), (2, 0.27755687)],\n",
      " [(0, 0.9222179), (1, 0.03970168), (2, 0.03808037)],\n",
      " [(0, 0.837722), (1, 0.08429482), (2, 0.07798323)],\n",
      " [(0, 0.845599), (1, 0.07791002), (2, 0.07649094)],\n",
      " [(0, 0.8356078), (1, 0.08485632), (2, 0.07953588)],\n",
      " [(0, 0.9006697), (1, 0.049793124), (2, 0.04953719)],\n",
      " [(0, 0.9068326), (1, 0.046273984), (2, 0.046893444)],\n",
      " [(0, 0.13853815), (1, 0.10915808), (2, 0.7523038)],\n",
      " [(0, 0.84701633), (1, 0.077133425), (2, 0.07585024)],\n",
      " [(0, 0.8466872), (1, 0.07662638), (2, 0.07668641)],\n",
      " [(0, 0.9015518), (1, 0.049056143), (2, 0.049392093)],\n",
      " [(0, 0.8993055), (1, 0.04975212), (2, 0.05094239)],\n",
      " [(0, 0.78035444), (1, 0.113220684), (2, 0.10642487)],\n",
      " [(0, 0.86872166), (1, 0.06717562), (2, 0.06410271)],\n",
      " [(0, 0.89705604), (1, 0.04917676), (2, 0.05376722)],\n",
      " [(0, 0.9033558), (1, 0.048016496), (2, 0.04862776)],\n",
      " [(0, 0.8926446), (1, 0.053242803), (2, 0.054112613)],\n",
      " [(0, 0.06710652), (1, 0.063061856), (2, 0.86983156)],\n",
      " [(0, 0.83015287), (1, 0.08176864), (2, 0.088078536)],\n",
      " [(0, 0.46911225), (1, 0.47998244), (2, 0.0509053)],\n",
      " [(0, 0.9210295), (1, 0.040913988), (2, 0.03805652)],\n",
      " [(0, 0.19667803), (1, 0.6111331), (2, 0.19218886)],\n",
      " [(0, 0.91481084), (1, 0.042835165), (2, 0.042354017)],\n",
      " [(0, 0.9011334), (1, 0.05058592), (2, 0.048280668)],\n",
      " [(0, 0.92263454), (1, 0.03939843), (2, 0.03796703)],\n",
      " [(0, 0.88904214), (1, 0.05451008), (2, 0.056447797)],\n",
      " [(0, 0.9037834), (1, 0.04792759), (2, 0.04828906)],\n",
      " [(0, 0.8981315), (1, 0.05118708), (2, 0.05068142)],\n",
      " [(0, 0.23348118), (1, 0.68599784), (2, 0.080520995)],\n",
      " [(0, 0.6656738), (1, 0.26719826), (2, 0.067127906)],\n",
      " [(0, 0.33333334), (1, 0.33333334), (2, 0.33333334)],\n",
      " [(0, 0.8731414), (1, 0.06394429), (2, 0.062914304)],\n",
      " [(0, 0.757257), (1, 0.12217322), (2, 0.120569766)],\n",
      " [(0, 0.8476385), (1, 0.07745122), (2, 0.07491035)],\n",
      " [(0, 0.8822021), (1, 0.05943224), (2, 0.058365673)],\n",
      " [(0, 0.59547776), (1, 0.20760943), (2, 0.1969128)],\n",
      " [(0, 0.89857024), (1, 0.051631924), (2, 0.049797837)],\n",
      " [(0, 0.9194909), (1, 0.04010727), (2, 0.040401865)],\n",
      " [(0, 0.84260976), (1, 0.07988376), (2, 0.077506505)],\n",
      " [(0, 0.88293153), (1, 0.058823757), (2, 0.058244716)],\n",
      " [(0, 0.61706173), (1, 0.19628508), (2, 0.18665315)],\n",
      " [(0, 0.8347298), (1, 0.080215834), (2, 0.08505443)],\n",
      " [(0, 0.14542826), (1, 0.3691944), (2, 0.48537737)],\n",
      " [(0, 0.059812706), (1, 0.060617786), (2, 0.8795695)],\n",
      " [(0, 0.8878282), (1, 0.05436622), (2, 0.05780565)],\n",
      " [(0, 0.05990401), (1, 0.88073224), (2, 0.05936375)],\n",
      " [(0, 0.6396834), (1, 0.18140242), (2, 0.17891414)],\n",
      " [(0, 0.8726306), (1, 0.06399203), (2, 0.06337732)],\n",
      " [(0, 0.86741185), (1, 0.065991245), (2, 0.06659693)],\n",
      " [(0, 0.86090535), (1, 0.0709071), (2, 0.06818753)],\n",
      " [(0, 0.8384741), (1, 0.080279954), (2, 0.08124598)],\n",
      " [(0, 0.8639212), (1, 0.065855175), (2, 0.07022357)],\n",
      " [(0, 0.88461894), (1, 0.057262406), (2, 0.05811868)],\n",
      " [(0, 0.04029866), (1, 0.9199305), (2, 0.03977083)],\n",
      " [(0, 0.91195333), (1, 0.044978682), (2, 0.043068025)],\n",
      " [(0, 0.12542675), (1, 0.766614), (2, 0.10795924)],\n",
      " [(0, 0.065964), (1, 0.8670983), (2, 0.066937715)],\n",
      " [(0, 0.06040148), (1, 0.87826043), (2, 0.061338108)],\n",
      " [(0, 0.814783), (1, 0.09314547), (2, 0.09207157)],\n",
      " [(0, 0.8969824), (1, 0.050776865), (2, 0.052240733)],\n",
      " [(0, 0.7022386), (1, 0.15753433), (2, 0.14022705)],\n",
      " [(0, 0.9143928), (1, 0.04344245), (2, 0.04216477)],\n",
      " [(0, 0.89792424), (1, 0.05360404), (2, 0.04847175)],\n",
      " [(0, 0.91285115), (1, 0.04367961), (2, 0.04346921)],\n",
      " [(0, 0.06813506), (1, 0.8630376), (2, 0.06882735)],\n",
      " [(0, 0.911414), (1, 0.044960532), (2, 0.04362541)],\n",
      " [(0, 0.8448041), (1, 0.07616029), (2, 0.07903559)],\n",
      " [(0, 0.89582485), (1, 0.054035205), (2, 0.050139915)],\n",
      " [(0, 0.90541816), (1, 0.047338936), (2, 0.047242925)],\n",
      " [(0, 0.8936443), (1, 0.053247195), (2, 0.053108506)],\n",
      " [(0, 0.8931975), (1, 0.054014128), (2, 0.0527884)],\n",
      " [(0, 0.9018465), (1, 0.05013562), (2, 0.048017904)],\n",
      " [(0, 0.8766572), (1, 0.062125053), (2, 0.06121774)],\n",
      " [(0, 0.9136971), (1, 0.04344025), (2, 0.042862643)],\n",
      " [(0, 0.5841751), (1, 0.21465959), (2, 0.20116529)],\n",
      " [(0, 0.9317962), (1, 0.03455141), (2, 0.033652443)],\n",
      " [(0, 0.9064751), (1, 0.045687705), (2, 0.04783719)],\n",
      " [(0, 0.9164746), (1, 0.041375186), (2, 0.04215024)],\n",
      " [(0, 0.557961), (1, 0.19261189), (2, 0.24942711)],\n",
      " [(0, 0.8677293), (1, 0.065566815), (2, 0.066703916)],\n",
      " [(0, 0.9062826), (1, 0.047258765), (2, 0.046458635)],\n",
      " [(0, 0.5957785), (1, 0.35463774), (2, 0.049583726)],\n",
      " [(0, 0.86795175), (1, 0.0659446), (2, 0.066103704)],\n",
      " [(0, 0.7986256), (1, 0.095550366), (2, 0.10582402)],\n",
      " [(0, 0.8012748), (1, 0.09487607), (2, 0.10384915)],\n",
      " [(0, 0.9145258), (1, 0.042797714), (2, 0.042676456)],\n",
      " [(0, 0.902979), (1, 0.04821618), (2, 0.04880484)],\n",
      " [(0, 0.90354455), (1, 0.048406664), (2, 0.04804876)],\n",
      " [(0, 0.91136545), (1, 0.04396067), (2, 0.044673838)],\n",
      " [(0, 0.896331), (1, 0.05170387), (2, 0.051965084)],\n",
      " [(0, 0.77079666), (1, 0.13167374), (2, 0.09752961)],\n",
      " [(0, 0.84692454), (1, 0.075080976), (2, 0.07799449)],\n",
      " [(0, 0.9029252), (1, 0.047631007), (2, 0.04944379)],\n",
      " [(0, 0.8416278), (1, 0.07899116), (2, 0.07938111)],\n",
      " [(0, 0.10823785), (1, 0.7870443), (2, 0.10471789)],\n",
      " [(0, 0.87043846), (1, 0.06529137), (2, 0.064270146)],\n",
      " [(0, 0.9087919), (1, 0.045704957), (2, 0.045503143)],\n",
      " [(0, 0.9180764), (1, 0.041079108), (2, 0.040844485)],\n",
      " [(0, 0.8669114), (1, 0.06947512), (2, 0.063613445)],\n",
      " [(0, 0.8997076), (1, 0.049261354), (2, 0.051031034)],\n",
      " [(0, 0.9183417), (1, 0.04138493), (2, 0.04027337)],\n",
      " [(0, 0.5462941), (1, 0.38745454), (2, 0.0662514)],\n",
      " [(0, 0.88275117), (1, 0.059523657), (2, 0.05772519)],\n",
      " [(0, 0.07451548), (1, 0.85293466), (2, 0.072549865)],\n",
      " [(0, 0.88939244), (1, 0.055631533), (2, 0.054976005)],\n",
      " [(0, 0.79577327), (1, 0.10095885), (2, 0.10326783)],\n",
      " [(0, 0.88462967), (1, 0.057878677), (2, 0.057491653)],\n",
      " [(0, 0.9228943), (1, 0.03929948), (2, 0.037806235)],\n",
      " [(0, 0.7378993), (1, 0.12728763), (2, 0.13481306)],\n",
      " [(0, 0.9206182), (1, 0.039023086), (2, 0.040358733)],\n",
      " [(0, 0.7233084), (1, 0.13412037), (2, 0.14257124)],\n",
      " [(0, 0.9001448), (1, 0.05020621), (2, 0.049649008)],\n",
      " [(0, 0.05101745), (1, 0.05296368), (2, 0.89601886)],\n",
      " [(0, 0.90234596), (1, 0.049363874), (2, 0.04829016)],\n",
      " [(0, 0.12717041), (1, 0.73516333), (2, 0.13766626)],\n",
      " [(0, 0.05041484), (1, 0.05071071), (2, 0.89887446)],\n",
      " [(0, 0.5022868), (1, 0.41875008), (2, 0.07896314)],\n",
      " [(0, 0.43073684), (1, 0.043134477), (2, 0.5261287)],\n",
      " [(0, 0.842973), (1, 0.078876354), (2, 0.07815067)],\n",
      " [(0, 0.08227617), (1, 0.085249804), (2, 0.83247405)],\n",
      " [(0, 0.8972863), (1, 0.04577231), (2, 0.056941386)],\n",
      " [(0, 0.8828516), (1, 0.058424614), (2, 0.0587238)],\n",
      " [(0, 0.8682724), (1, 0.065092474), (2, 0.0666351)],\n",
      " [(0, 0.50796694), (1, 0.4177819), (2, 0.074251145)],\n",
      " [(0, 0.55517846), (1, 0.25108895), (2, 0.19373259)],\n",
      " [(0, 0.6396071), (1, 0.18144949), (2, 0.17894344)],\n",
      " [(0, 0.87719804), (1, 0.05920758), (2, 0.06359435)],\n",
      " [(0, 0.33333334), (1, 0.33333334), (2, 0.33333334)],\n",
      " [(0, 0.8357472), (1, 0.0800263), (2, 0.08422654)],\n",
      " [(0, 0.5639399), (1, 0.2178145), (2, 0.21824557)],\n",
      " [(0, 0.14461903), (1, 0.14576922), (2, 0.7096118)],\n",
      " [(0, 0.7395047), (1, 0.12861437), (2, 0.13188091)],\n",
      " [(0, 0.7231113), (1, 0.12683646), (2, 0.15005223)],\n",
      " [(0, 0.23071334), (1, 0.20884816), (2, 0.56043845)],\n",
      " [(0, 0.9007406), (1, 0.049731415), (2, 0.049527984)],\n",
      " [(0, 0.106255144), (1, 0.10501596), (2, 0.7887289)],\n",
      " [(0, 0.8101168), (1, 0.09592046), (2, 0.09396273)],\n",
      " [(0, 0.7865663), (1, 0.10249551), (2, 0.110938184)],\n",
      " [(0, 0.1133741), (1, 0.77712214), (2, 0.109503806)],\n",
      " [(0, 0.74803436), (1, 0.12614161), (2, 0.12582405)],\n",
      " [(0, 0.8782174), (1, 0.06326374), (2, 0.058518894)],\n",
      " [(0, 0.06790553), (1, 0.06534716), (2, 0.8667473)],\n",
      " [(0, 0.90202093), (1, 0.051242404), (2, 0.046736717)],\n",
      " [(0, 0.08563527), (1, 0.8350153), (2, 0.07934948)],\n",
      " [(0, 0.882035), (1, 0.060996693), (2, 0.05696824)],\n",
      " [(0, 0.80475426), (1, 0.09461887), (2, 0.10062685)],\n",
      " [(0, 0.8886899), (1, 0.056045786), (2, 0.055264335)],\n",
      " [(0, 0.880566), (1, 0.058631565), (2, 0.06080245)],\n",
      " [(0, 0.8871193), (1, 0.05685603), (2, 0.05602468)],\n",
      " [(0, 0.62547785), (1, 0.18874894), (2, 0.18577322)],\n",
      " [(0, 0.8960223), (1, 0.052454583), (2, 0.05152311)],\n",
      " [(0, 0.57721716), (1, 0.2063214), (2, 0.21646148)],\n",
      " [(0, 0.9106584), (1, 0.044393454), (2, 0.04494816)],\n",
      " [(0, 0.3384006), (1, 0.6042199), (2, 0.05737943)],\n",
      " [(0, 0.7370439), (1, 0.13252757), (2, 0.13042848)],\n",
      " [(0, 0.8413231), (1, 0.07983333), (2, 0.07884358)],\n",
      " [(0, 0.91299915), (1, 0.044741683), (2, 0.04225914)],\n",
      " [(0, 0.8418953), (1, 0.07789271), (2, 0.08021203)],\n",
      " [(0, 0.06511652), (1, 0.8680088), (2, 0.06687468)],\n",
      " [(0, 0.79047614), (1, 0.104857944), (2, 0.10466588)],\n",
      " [(0, 0.8790339), (1, 0.059734408), (2, 0.061231665)],\n",
      " [(0, 0.7549254), (1, 0.19478568), (2, 0.050288983)],\n",
      " [(0, 0.61267513), (1, 0.20150264), (2, 0.18582217)],\n",
      " [(0, 0.14260688), (1, 0.108595006), (2, 0.74879813)],\n",
      " [(0, 0.11062267), (1, 0.0963704), (2, 0.79300696)],\n",
      " [(0, 0.05999251), (1, 0.88247466), (2, 0.057532795)],\n",
      " [(0, 0.113438286), (1, 0.052977603), (2, 0.83358413)],\n",
      " [(0, 0.8281086), (1, 0.08842923), (2, 0.08346218)],\n",
      " [(0, 0.33333334), (1, 0.33333334), (2, 0.33333334)]]\n"
     ]
    }
   ],
   "source": [
    "# unseen_document = 'if you love traveling, you\\'ll love this'\n",
    "# bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "# for index, score in sorted(lda_model_tfidf[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "#     topic = lda_model_tfidf.print_topic(index, 10)\n",
    "#     print(\"Score: {}\\t Topic words:{}\".format(score, re.sub('[^A-Za-z]+', ',', topic)))\n",
    "\n",
    "# adapted from https://towardsdatascience.com/unsupervised-nlp-topic-models-as-a-supervised-learning-input-cf8ee9e5cf28\n",
    "unseen_df = pd.read_csv(test_path)\n",
    "\n",
    "train_vecs = []\n",
    "for text_entry in unseen_df['text']:\n",
    "    bow_vector = dictionary.doc2bow(preprocess(text_entry))\n",
    "    top_topics = (\n",
    "        lda_model_tfidf.get_document_topics(bow_vector,\n",
    "                                        minimum_probability=0.0)\n",
    "    )\n",
    "\n",
    "    # probabilities for topics 0-num_topics, unsorted\n",
    "    train_vecs.append(top_topics)\n",
    "    \n",
    "\n",
    "pprint(train_vecs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let’s say I had an apple, and you had an orang...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an apple.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We could trade, and both of us would end up ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But now let’s say I had an apple tree, and you...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the apple tree were ready, but the oranges wou...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  topics\n",
       "0  Let’s say I had an apple, and you had an orang...       2\n",
       "1                                          an apple.       2\n",
       "2  We could trade, and both of us would end up ha...       0\n",
       "3  But now let’s say I had an apple tree, and you...       2\n",
       "4  the apple tree were ready, but the oranges wou...       2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results = []\n",
    "for doc in train_vecs:\n",
    "    topic_idx, score = max(doc, key=lambda x: x[1]) # numerical topic\n",
    "    topic_results.append(topic_idx)\n",
    "    # topic = lda_model_tfidf.print_topic(topic_idx, 10)      # topic words\n",
    "    # print(re.sub('[^A-Za-z]+', ',', topic))                 # top words in this topic\n",
    "\n",
    "unseen_df['topics'] = topic_results\n",
    "unseen_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_df.to_csv(topic_path, sep=',', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
